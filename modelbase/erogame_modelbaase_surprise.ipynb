{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## メモ\n",
        "\n",
        "回帰分析の評価指標\n",
        "\n",
        "* https://stats.biopapyrus.jp/glm/lm-evaluation.html\n",
        "\n",
        "ユークリッド距離 vs コサイン類似度\n",
        "\n",
        "* https://enjoyworks.jp/tech-blog/2242\n",
        "\n",
        "ライブラリ使った方が楽そう\n",
        "\n",
        "* https://github.com/NicolasHug/Surprise\n",
        "\n",
        "レコメンドサンプル\n",
        "\n",
        " * https://github.com/NicolasHug/Surprise/blob/master/examples/top_n_recommendations.py\n",
        "\n",
        "Python surprise で作る らくらく「レコメンドエンジン」（その１）\n",
        "\n",
        "* https://www.salesanalytics.co.jp/datascience/datascience180/"
      ],
      "metadata": {
        "id": "SddIGooQuC6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install surprise"
      ],
      "metadata": {
        "id": "u1eW626osOF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JeNXmIfoFce"
      },
      "outputs": [],
      "source": [
        "from surprise import NMF, Dataset, accuracy, Reader\n",
        "from surprise.model_selection import train_test_split, cross_validate\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0の部分は未知\n",
        "ratings_dict = {\n",
        "    \"itemID\": [1, 1, 1, 2, 2],\n",
        "    \"userID\": [9, 32, 2, 45, 2],\n",
        "    \"rating\": [3, 2, 4, 3, 1],\n",
        "}\n",
        "df = pd.DataFrame(ratings_dict)"
      ],
      "metadata": {
        "id": "HfDF6wC7rOwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "6gu2JXJdBNMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo=NMF()\n",
        "reader = Reader()\n",
        "data = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]],reader)"
      ],
      "metadata": {
        "id": "7EzVLjeeupHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(algo, data, measures=['RMSE','MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "JA_ptBGr1m9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------"
      ],
      "metadata": {
        "id": "X3do5fnVAkYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install surprise"
      ],
      "metadata": {
        "id": "23ICAK8dAmq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import NMF, SVD, SVDpp, Dataset, accuracy, Reader\n",
        "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "from google.colab import drive\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "metadata": {
        "id": "qvM-ruMJAppM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fbyVcfq6ApnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_tmp_df = pd.read_csv('drive/My Drive/dev/20230424_recommend_erogame/userbase_matrix.csv', encoding='utf-8')\n",
        "user_df = pd.read_csv('drive/My Drive/dev/20230424_recommend_erogame/userbase_user_map.csv', encoding='utf-8')\n",
        "game_df = pd.read_csv('drive/My Drive/dev/20230424_recommend_erogame/userbase_game_map.csv', encoding='utf-8')\n",
        "scores_df = pd.read_csv('drive/My Drive/dev/20230424_recommend_erogame/score_df_pickupuser_202310.csv' ,encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "L-SA_8hCAvC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ユーザー数：\" + str(len(user_df)))\n",
        "print(\"ゲーム数：\" + str(len(game_df)))"
      ],
      "metadata": {
        "id": "y02mQR54sCqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 評価数を全ユーザー合わせる\n",
        "def random_pickupitem(df, max_item):\n",
        "  dic = {}\n",
        "  result_df = df.copy()\n",
        "  for index, tmp in df.iterrows():\n",
        "    if tmp.uid not in dic:\n",
        "      dic[tmp.uid] = []\n",
        "    dic[tmp.uid].append(index)\n",
        "  for key in dic:\n",
        "    delete_num = len(dic[key]) - max_item\n",
        "    if delete_num == 0:\n",
        "      continue\n",
        "    delete_keys = random.sample(dic[key], delete_num)\n",
        "    result_df.drop(index = delete_keys,inplace=True)\n",
        "  return result_df\n",
        "scores_df_pickupitem = random_pickupitem(scores_tmp_df,20)\n",
        "# 時間かかるのでファイル化\n",
        "scores_df_pickupitem.to_csv('drive/My Drive/dev/20230424_recommend_erogame/score_df_pickupitem_202310.csv', index=False)"
      ],
      "metadata": {
        "id": "C5staJIlI_dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ユーザーを抽出\n",
        "def random_pickupuser(df, max_user):\n",
        "  del_list = []\n",
        "  result_df = df.copy()\n",
        "  delete_num = len(df['uid'].unique()) - max_user\n",
        "  del_list = random.sample(df['uid'].unique().tolist(), delete_num)\n",
        "  for key in del_list:\n",
        "    delete_keys = df[df['uid']==key].index\n",
        "    result_df.drop(index = delete_keys,inplace=True)\n",
        "  return result_df\n",
        "scores_df = random_pickupuser(scores_df_pickupitem,2000)\n",
        "# 時間かかるのでファイル化\n",
        "scores_df.to_csv('drive/My Drive/dev/20230424_recommend_erogame/score_df_pickupuser_202310.csv', index=False)"
      ],
      "metadata": {
        "id": "j0KvFI2SaOX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(scores_df[scores_df['uid']==8].index)\n",
        "# len(scores_df['uid'].unique())\n",
        "random.sample(scores_df['uid'].unique().tolist(),1)"
      ],
      "metadata": {
        "id": "ZUBRhqhDSVqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions(list of Prediction objects): The list of predictions, as\n",
        "            returned by the test method of an algorithm.\n",
        "        n(int): The number of recommendation to output for each user. Default\n",
        "            is 10.\n",
        "\n",
        "    Returns:\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
        "        [(raw item id, rating estimation), ...] of size n.\n",
        "    \"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    count = 0\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "k9tkLN-SPrVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info(list, target_user_index):\n",
        "  print(\"user_id : \" + user_df.iloc[target_user_index].uid + \" - https://erogamescape.dyndns.org/~ap2/ero/toukei_kaiseki/user_infomation.php?user=\" + user_df.iloc[target_user_index].uid)\n",
        "  for tmp in list[target_user_index]:\n",
        "    if tmp[0] in scores_tmp_df[scores_tmp_df['uid']==target_user_index].game_id.values:\n",
        "      continue\n",
        "    print(\"game_id : \" + str(tmp[0]) + \"-\" + str(game_df.iloc[tmp[0]].game_id) + \" - \" + str(tmp[1]) + \" - https://erogamescape.dyndns.org/~ap2/ero/toukei_kaiseki/game.php?game=\" + str(game_df.iloc[tmp[0]].game_id))"
      ],
      "metadata": {
        "id": "_SS3df3Ad_Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader()\n",
        "data = Dataset.load_from_df(scores_df[[\"uid\", \"game_id\", \"score\"]],reader)"
      ],
      "metadata": {
        "id": "rWP1l30IBB0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの調整\n",
        "param_grid = {\"n_factors\":[20, 50, 100], \"n_epochs\": [10, 25, 50], \"lr_all\": [0.002, 0.005 ,0.01]}\n",
        "gs = GridSearchCV(SVDpp, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score[\"rmse\"])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params[\"rmse\"])"
      ],
      "metadata": {
        "id": "h0X0_NTmUCtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo=SVDpp(n_factors=20,n_epochs=25,lr_all=0.005)"
      ],
      "metadata": {
        "id": "GNhPgLyYFyQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(algo, data, measures=['RMSE','MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "JavJTIXyBnqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = data.build_full_trainset()\n",
        "testset = trainset.build_anti_testset()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)"
      ],
      "metadata": {
        "id": "tK91oAI6boK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10 = get_top_n(predictions, 20)"
      ],
      "metadata": {
        "id": "t0cohgAlbjR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_tmp_df[scores_tmp_df['uid']==4682].game_id.values"
      ],
      "metadata": {
        "id": "-09lPkejluXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_info(top_10, 4682)"
      ],
      "metadata": {
        "id": "cq4rr35gdxvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}