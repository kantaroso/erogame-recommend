{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## メモ\n",
        "\n",
        "回帰分析の評価指標\n",
        "\n",
        "* https://stats.biopapyrus.jp/glm/lm-evaluation.html\n",
        "\n",
        "ユークリッド距離 vs コサイン類似度\n",
        "\n",
        "* https://enjoyworks.jp/tech-blog/2242\n",
        "\n",
        "ライブラリ使った方が楽そう\n",
        "\n",
        "* https://github.com/NicolasHug/Surprise\n",
        "\n",
        "レコメンドサンプル\n",
        "\n",
        " * https://github.com/NicolasHug/Surprise/blob/master/examples/top_n_recommendations.py\n",
        "\n",
        "Python surprise で作る らくらく「レコメンドエンジン」（その１）\n",
        "\n",
        "* https://www.salesanalytics.co.jp/datascience/datascience180/"
      ],
      "metadata": {
        "id": "SddIGooQuC6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install surprise"
      ],
      "metadata": {
        "id": "u1eW626osOF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JeNXmIfoFce"
      },
      "outputs": [],
      "source": [
        "from surprise import NMF, Dataset, accuracy, Reader\n",
        "from surprise.model_selection import train_test_split, cross_validate\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0の部分は未知\n",
        "ratings_dict = {\n",
        "    \"itemID\": [1, 1, 1, 2, 2],\n",
        "    \"userID\": [9, 32, 2, 45, 2],\n",
        "    \"rating\": [3, 2, 4, 3, 1],\n",
        "}\n",
        "df = pd.DataFrame(ratings_dict)"
      ],
      "metadata": {
        "id": "HfDF6wC7rOwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "6gu2JXJdBNMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo=NMF()\n",
        "reader = Reader()\n",
        "data = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]],reader)"
      ],
      "metadata": {
        "id": "7EzVLjeeupHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(algo, data, measures=['RMSE','MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "JA_ptBGr1m9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------"
      ],
      "metadata": {
        "id": "X3do5fnVAkYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install surprise"
      ],
      "metadata": {
        "id": "23ICAK8dAmq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import NMF, SVD, SVDpp, Dataset, accuracy, Reader\n",
        "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
        "from google.colab import drive\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qvM-ruMJAppM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fbyVcfq6ApnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df = pd.read_csv('drive/My Drive/dev/20230424_recommend_erogame/userbase_matrix.csv', encoding='utf-8')\n",
        "user_df = pd.read_csv('drive/My Drive/dev/20230424_recommend_erogame/userbase_user_map.csv', encoding='utf-8')\n",
        "game_df = pd.read_csv('drive/My Drive/dev/20230424_recommend_erogame/userbase_game_map.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "L-SA_8hCAvC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions(list of Prediction objects): The list of predictions, as\n",
        "            returned by the test method of an algorithm.\n",
        "        n(int): The number of recommendation to output for each user. Default\n",
        "            is 10.\n",
        "\n",
        "    Returns:\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
        "        [(raw item id, rating estimation), ...] of size n.\n",
        "    \"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "k9tkLN-SPrVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info(list, target_user_index):\n",
        "  print(\"user_id : \" + user_df.iloc[target_user_index].uid + \" - https://erogamescape.dyndns.org/~ap2/ero/toukei_kaiseki/user_infomation.php?user=\" + user_df.iloc[target_user_index].uid)\n",
        "  for tmp in list[target_user_index]:\n",
        "    print(\"game_id : \" + str(game_df.iloc[tmp[0]].game_id) + \" - \" + str(tmp[1]) + \" - https://erogamescape.dyndns.org/~ap2/ero/toukei_kaiseki/game.php?game=\" + str(game_df.iloc[tmp[0]].game_id))"
      ],
      "metadata": {
        "id": "_SS3df3Ad_Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_df.iloc[0].uid)"
      ],
      "metadata": {
        "id": "JPh-Ec_pBVSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader()\n",
        "data = Dataset.load_from_df(scores_df[[\"uid\", \"game_id\", \"score\"]],reader)"
      ],
      "metadata": {
        "id": "rWP1l30IBB0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの調整\n",
        "param_grid = {\"n_factors\":[20, 50, 100], \"n_epochs\": [10, 25, 50], \"lr_all\": [0.002, 0.005 ,0.01]}\n",
        "gs = GridSearchCV(SVDpp, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
        "\n",
        "gs.fit(data)\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score[\"rmse\"])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params[\"rmse\"])"
      ],
      "metadata": {
        "id": "h0X0_NTmUCtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo=SVDpp(n_factors=20,n_epochs=25,lr_all=0.005)"
      ],
      "metadata": {
        "id": "GNhPgLyYFyQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(algo, data, measures=['RMSE','MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "JavJTIXyBnqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = data.build_full_trainset()\n",
        "testset = trainset.build_anti_testset()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)"
      ],
      "metadata": {
        "id": "tK91oAI6boK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10 = get_top_n(predictions)"
      ],
      "metadata": {
        "id": "t0cohgAlbjR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_info(top_10, 300)"
      ],
      "metadata": {
        "id": "cq4rr35gdxvW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}